{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bbe84fd-3166-49ef-b478-55c15ce66707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's think step by step (by default support with gpt-4 < models), is a prompt to let the model think more logically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b60ebc0f-2b79-499b-9571-4ad1dad976db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "644362d2-02a9-45d5-8527-528e556113d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4daa7b43-30d3-468e-b0e8-130acbbaf630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c79e0f-52b1-40ba-acdf-5ad5dbd65f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d80a174-5650-41f4-9922-840c20e815ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1aa85d-cccb-4aac-a5bf-e64ddccf550b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eec035-1afc-454c-bcef-9d129c390351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08c9299a-3297-4cf7-bd80-4d791b202dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3008457-5112-442d-b9d5-81bc43cb0829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here without step by step thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66eb382f-092c-40c2-84c3-3673c3c9090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= \"\"\"\n",
    "\n",
    "I'm 5 years older than Ahmed, and Ahmed is 3 years younger than Rami, who is 30 years old, how old am I\n",
    "\n",
    "\n",
    "don't think step by step\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7171efb-2bd9-47ee-a8e1-d15ba2f19c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\":\"user\", \"content\": prompt}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffe44180-afc3-479e-9235-2723d8a55d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are 33 years old.\n"
     ]
    }
   ],
   "source": [
    "print(res.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2eff75b7-22d6-42de-b1da-9ee6d8dae74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with \"let's think step by step\" instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "752edc0b-2e3a-40cc-8e24-be2b6197d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "\n",
    "I'm 5 years older than Ahmed, and Ahmed is 3 years younger than Rami, who is 30 years old, how old am I\n",
    "\n",
    "\n",
    "let's think step by step\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff3e74e5-4fb4-49e5-84c3-dc518c3fa934",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": prompt}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "408938c7-9445-4e0b-bddc-bbcb5da96826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's solve the problem step by step.\n",
      "\n",
      "1. We know that Rami is 30 years old.\n",
      "2. Ahmed is 3 years younger than Rami. So, we can calculate Ahmed's age:\n",
      "   \\[\n",
      "   \\text{Ahmed's age} = \\text{Rami's age} - 3 = 30 - 3 = 27 \\text{ years old}\n",
      "   \\]\n",
      "\n",
      "3. You are 5 years older than Ahmed. Now, we can calculate your age:\n",
      "   \\[\n",
      "   \\text{Your age} = \\text{Ahmed's age} + 5 = 27 + 5 = 32 \\text{ years old}\n",
      "   \\]\n",
      "\n",
      "So, you are **32 years old**.\n"
     ]
    }
   ],
   "source": [
    "print(res.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
